{
  "hash": "5d39a2df305c966d568aa2a58f901304",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Using R to create column charts featuring 95% confidence intervals\"\ndate: \"5 January 2022\"\ndate-modified: \"27 July 2024\"\ncategories:\n  - Statistics\n  - tidyverse\n  - ggplot2\n  - Public Health\nauthor: Daniel Weiand\nsubtitle: >\n---\n\n### **Daniel Weiand – Consultant Medical Microbiologist – Newcastle upon Tyne NHS Foundation Trust**\n\nHello!\n\nThis is my first blog post for the NHS R Community, which I stumbled across in the course of my work as a consultant medical microbiologist at Newcastle upon Tyne Hospitals NHS Foundation Trust.\n\nAt work, I've been trying to use R to create column charts featuring 95% confidence intervals. I approached the friendly people on the NHS R Community's Slack channel for further information and guidance.\n\nI must add here that the Community's Slack channel has been extremely helpful to me, as a novice R user, in solving some of the issues I've experienced, and highlighting R packages of potential interest. This is the first time I've tried to create a ReprEx and now I understand why people love (?) the mtcars database as much as they do!\n\n### **Step 1: Calculate some summary statistics**\n\nI wanted to calculate some summary statistics, including the mean, and standard error or 95% confidence intervals.\n\nInitially I came across the `summary()` function of Base R, which is helpful as it calculates the `Min.`, `1st Qu.`, `Median`, `Mean`, `3rd Qu.`, and `Max`.\n\nHowever, the `summary()` function of {base} R does not calculate either the standard error or the 95% confidence intervals:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n# calculate summary statistics for all numeric data using summary() and where(is.numeric())\nmtcars %>%\n  select(where(is.numeric)) %>%\n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      mpg             cyl             disp             hp       \n Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0  \n 1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5  \n Median :19.20   Median :6.000   Median :196.3   Median :123.0  \n Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7  \n 3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0  \n Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0  \n      drat             wt             qsec             vs        \n Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :0.0000  \n 1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:0.0000  \n Median :3.695   Median :3.325   Median :17.71   Median :0.0000  \n Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :0.4375  \n 3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:1.0000  \n Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :1.0000  \n       am              gear            carb      \n Min.   :0.0000   Min.   :3.000   Min.   :1.000  \n 1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:2.000  \n Median :0.0000   Median :4.000   Median :2.000  \n Mean   :0.4062   Mean   :3.688   Mean   :2.812  \n 3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :1.0000   Max.   :5.000   Max.   :8.000  \n```\n\n\n:::\n\n```{.r .cell-code}\n# calculate summary statistics for mpg using summary() and where(is.numeric())\nmtcars %>%\n  select(mpg) %>%\n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      mpg       \n Min.   :10.40  \n 1st Qu.:15.43  \n Median :19.20  \n Mean   :20.09  \n 3rd Qu.:22.80  \n Max.   :33.90  \n```\n\n\n:::\n:::\n\n\nThen zx8754 very kindly pointed me towards a method for calculating the standard error on StackOverflow: <https://stackoverflow.com/q/2676554/680068>\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create stderr function\nstderr <- function(x, na.rm = TRUE) {\n if (na.rm) x <- na.omit(x)\n sqrt(var(x)/length(x))\n}\n```\n:::\n\n\nThen I used this function to calculate summary statistics, incl. mean and standard error, using the `summarise()` and `across()` functions of {dplyr}:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# calculate summary statistics using summarise() and across() and n/mean/min/median/max/sd/stderr\n# stderr <- function(x, na.rm=TRUE) {\n#  if (na.rm) x <- na.omit(x)\n#  sqrt(var(x)/length(x))\n# }\nmtcars %>% \n group_by(cyl) %>% \n mutate(\n   across(mpg, \n          list(\n            n = ~ n(),\n            mean = ~ mean(.x, na.rm = TRUE),\n            min = ~ min(.x, na.rm = TRUE),\n            median = ~ median(.x, na.rm = TRUE),\n            max = ~ max(.x, na.rm = TRUE),\n            sd = ~ sd(.x, na.rm = TRUE),\n            stderr = ~ stderr(.x)),\n          .names = NULL)) %>%\n select(starts_with(\"mpg\")) %>% \n summarise(mean = mean(mpg_mean),\n           min = mean(mpg_min),\n           median = mean(mpg_median),\n           max = mean(mpg_max),\n           sd = mean(mpg_sd),\n           stderr = mean(mpg_stderr)) %>% \n#create column chart with error bars (using stderr) \n ggplot(aes(cyl, mean))+\n geom_col(na.rm = TRUE)+\n geom_errorbar(aes(ymin = mean-stderr, ymax = mean + stderr), \n               position = \"dodge\", width = 0.25)\n```\n\n::: {.cell-output-display}\n![](using-r-to-create-column-charts-featuring-95-confidence-intervals_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#calculate summary statistics using summarise() and across() and n/mean/min/median/max/sd/stderr\n# stderr <- function(x, na.rm=TRUE) {\n#  if (na.rm) x <- na.omit(x)\n#  sqrt(var(x)/length(x))\n# }\nmtcars %>% \n group_by(cyl) %>% \n mutate(\n   across(mpg, \n          list(\n            n = ~ n(),\n            mean = ~ mean(.x, na.rm = TRUE),\n            min = ~ min(.x, na.rm = TRUE),\n            median = ~ median(.x, na.rm = TRUE),\n            max = ~ max(.x, na.rm = TRUE),\n            sd = ~ sd(.x, na.rm = TRUE),\n            stderr = ~ stderr(.x)),\n          .names = NULL)) %>%\n select(starts_with(\"mpg\")) %>% \n summarise(mean = mean(mpg_mean),\n           min = mean(mpg_min),\n           median = mean(mpg_median),\n           max = mean(mpg_max),\n           sd = mean(mpg_sd),\n           stderr = mean(mpg_stderr)) %>% \n#create column chart with error bars (using stderr) \n ggplot(aes(cyl, mean))+\n geom_col(na.rm = TRUE)+\n geom_errorbar(aes(ymin = mean-stderr, ymax = mean + stderr), \n               position = \"dodge\", width = 0.25)\n```\n\n::: {.cell-output-display}\n![](using-r-to-create-column-charts-featuring-95-confidence-intervals_files/figure-html/unnamed-chunk-3-2.png){width=672}\n:::\n:::\n\n\n### **Step 2: Create column charts with error bars (using 95% confidence intervals)**\n\nThen Seb Fox pointed me towards a method for calculating 95% confidence intervals using the {PHEindicatormethods} package, available on CRAN: <https://cran.r-project.org/web/packages/PHEindicatormethods/index.html>\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create MEAN column chart with error bars (using 95% confidence intervals) \nrequire(PHEindicatormethods)\n\nmtcars %>% \n filter(!is.na(cyl)) %>% \n group_by(cyl) %>% \n#use phe_mean()\n phe_mean(x = mpg, # field name from data containing the values to calculate the means for\n          type = \"full\", # defines the data and metadata columns to be included in output; can be \"value\", \"lower\", \"upper\", \"standard\" (for all data) or \"full\" (for all data and metadata); quoted string; default = \"full\"\n          confidence = 0.95) %>% #required level of confidence expressed as a number between 0.9 and 1\n  \n# create column chart with error bars (using 95% CI calculated using phe_mean())\n ggplot(aes(cyl, value))+\n geom_col(na.rm = TRUE)+\n geom_errorbar(aes(ymin = lowercl, ymax = uppercl), \n               position = \"dodge\", width = 0.25)\n```\n\n::: {.cell-output-display}\n![](using-r-to-create-column-charts-featuring-95-confidence-intervals_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# create PROPORTION column chart with error bars (using 95% confidence intervals) \nrequire(PHEindicatormethods)\n\nmtcars %>% \n group_by(cyl) %>% \n summarise(n = n(),\n           sum = sum(n)) %>% \n mutate(sum = sum(n)) %>%\n# phe_proportion()\n phe_proportion(x = n, # numerator\n                n = sum, # denominator\n                type = \"full\", # defines the data and metadata columns to be included in output; can be \"value\", \"lower\", \"upper\", \"standard\" (for all data) or \"full\" (for all data and metadata); quoted string; default = \"full\"\n                confidence = 0.95, # required level of confidence expressed as a number between 0.9 and 1 \n                multiplier = 100) %>%   # the multiplier used to express the final values (for example 100 = percentage); numeric; default 1\n# create column chart with error bars (using 95% CI calculated using phe_proportion())\n ggplot(aes(cyl, value))+\n geom_col(na.rm = TRUE)+\n geom_errorbar(aes(ymin = lowercl, ymax = uppercl), \n               position = \"dodge\", width = 0.25)\n```\n\n::: {.cell-output-display}\n![](using-r-to-create-column-charts-featuring-95-confidence-intervals_files/figure-html/unnamed-chunk-4-2.png){width=672}\n:::\n:::\n\n\nI hope that the code, above, helps a few colleagues of mine across the NHS, in some small way.\n\nThank you, again, to all members of the NHS R Community, for all your help. Particular thanks go to everyone who has helped me, to date, on the NHS R Community's Slack channel.\n\n### **Comments (3)**\n\n1.  **Chuck Burks**\n\n    5 January 2022\n\n    I used to use a function like that, then I realized that I could get a function for standard error through the FSA package, `FSA::se()`. Arguments can be made either way; why reinvent the wheel vs. why load a large package to avoid writing one function.\n\n2.  **Qin Zeng**\n\n    5 January 2022\n\n    This works out about the same: `mtcars %>% group_by(cyl) %>% summarise_at(vars(mpg), funs(n(), mean, min, median, max, sd, stderr)) %>% ggplot(aes(cyl, mean))+ geom_col(na.rm = TRUE)+ geom_errorbar(aes(ymin = mean-stderr, ymax = mean+stderr), position = \"dodge\", width = 0.25)`\n\n3.  **Stephen**\n\n    6 January 2022\n\n    Two suggestions: `mtcars %>% group_by(cyl) %>% summarise(n = n(), sum = sum(n)) %>% mutate(sum = sum(n))` is more easily said as `mtcars %>% count(cyl) %>% mutate(sum = sum(n))` Qin, your sequence is better as mtcars %\\>% group_by(cyl) %\\>% summarise(n(), across(mpg, c(mean, min, median, max, sd, stdeQi, in modern dplyr (summarise_at is deprecated)\n",
    "supporting": [
      "using-r-to-create-column-charts-featuring-95-confidence-intervals_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}