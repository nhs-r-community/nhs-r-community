{
  "hash": "df34a03b0fb737d62f918e9ea991a98d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Designing my first Shiny dashboard\"\ndate: \"14 October 2021\"\ndate-modified: \"27 July 2024\"\ncategories:\n  - Shiny\n  - Functions\n  - tidyverse\n  - base R\n  - GIS\n  - zoo\n  - plotly\nauthor: Pablo Leon-Rodenas\nexecute: \n  eval: false\nsubtitle: >\n---\n\n::: {.callout-warning collapse=\"false\" appearance=\"default\" icon=\"true\"}\n## Archived data\nThe code in this blog will not work as the files have been renamed for archiving.\n\nUpdated code can be found at [Pablo's Github Repository](https://github.com/Pablo-source/Shiny-app-using-COVID-data)\n:::\n\n### **Project structure**\n\nThe aim of this blog article is to describe the initial experience of creating a Shiny dashboard this process involved a bit of reading on markdown documents and Shiny apps to learn how to code it.\n\nWhen designing this dashboard, I aimed to cover the following basic steps:\n\n-   Download open data from a Github Repository\n\n-   Create several indicators with their population rates by using World Band API\n\n-   Use {plotly} library for interactive plots to animate charts and maps in the Shiny app\n\n-   Build a Shiny dashboard containing different visualizations types\n\nBelow there is a detailed description of the steps followed to design the app.\n\n#### **1. Download COVID19 data**\n\nWhen creating any dashboard, I would like to feed daily data to it and also update it as soon as that data becomes available. Since the start of the pandemic, many resources have become available to analyze and visualize information about cases and deaths on different countries worldwide, so I decided to use JHU Github \\[<https://github.com/CSSEGISandData/COVID-19/archive/master.zip>\\] to download daily data.\n\nThe script below selects daily confirmed, death and recovered COVID-19 cases, downloads it and compresses them. Finally it extracts the relevant indicators (confirmed, death and recovered cases) as `.csv` files.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDownloadCOVIDData <- function() {\n  # Create data directory if doesn't exist\n  if (!dir.exists(\"data\")) {\n    dir.create(\"data\")\n  }\n  # Download master.zip file\n  download.file(\n    url = \"https://github.com/CSSEGISandData/COVID-19/archive/master.zip\",\n    destfile = \"data/covid19JH.zip\"\n  )\n  data_path <- \"COVID-19-master/csse_covid_19_data/csse_covid_19_time_series/\"\n\n  # Unzip covid19JH.zip file to extract .csv metric files (confirmed, deaths, recovered)\n  # time_series_covid19_confirmed_global.csv, time_series_covid19_deaths_global.csv,\n  # time_series_covid19_recovered_global.csv\n  unzip(\n    zipfile = \"data/covid19JH.zip\",\n    files = paste0(data_path, c(\n      \"time_series_covid19_confirmed_global.csv\",\n      \"time_series_covid19_deaths_global.csv\",\n      \"time_series_covid19_recovered_global.csv\"\n    )),\n    exdir = \"data\",\n    junkpaths = T\n  )\n}\n\nDownloadCOVIDData()\n```\n:::\n\n\nThen I had to update that initial download every half an hour, in case the file was updated throughout the day. In order to get the most up to date info, I thought of running it I though about this script to be run on a server or VM seven days a week, so it will periodically check to get the most up to date information.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDataupdate <- function() {\n  T_refresh <- 0.5 # hours\n  if (!dir_exists(\"data\")) {\n    dir.create(\"data\")\n    DownloadCOVIDData()\n  } else if ((!file.exists(\"data/covid19JH.zip\")) || as.double(Sys.time() - file_info(\"data/covid19JH.zip\")$change_time, units = \"hours\") > T_refresh) {\n    # If the latest refresh exceeds 30 minutes, then you download it again\n    DownloadCOVIDData()\n  }\n}\n\nDataupdate()\n```\n:::\n\n\nOnce the data was downloaded, I did some cleansing and data transformations from wide to long format, and also included new calculations with popularization data extracted from the World Bank API to create each of the indicators as rates per 10,000 population, using seven days rolling average to obtain an average of those daily indicators.\n\n#### **2. Create new metrics from raw covid data**\n\nAfter downloading the original data files, I extracted and assigned names to the three metrics I will use in the dashboard (data_confirmed,data_deceased,data_recovered).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninput_covid <- list.files(\"data/\", \".csv\")\n\nNFILES <- length(input_covid)\nfile_Name <- c(\"data_confirmed\", \"data_deceased\", \"data_recovered\", \"WDI_indicators\")\n\nfor (i in 1:NFILES) {\n  assign(\n    paste0(file_Name[i]), # Read and store data frames\n    read_csv(paste0(\n      \"data/\",\n      input_covid[i]\n    ))\n  )\n}\n```\n:::\n\n\n#### **3. Reshape data for plots**\n\nOriginally, the data is created in wide format and I transformed it into long format, including some calculations. I also aggregated it to Country level and applied relevant date format to display time series data and animations using a timeline in maps.\n\nFor the purpose of this blog post, I will only describe this process for one metric *COVID19 Confirmed cases*, the code for remaining two metrics (deceased cases, recovered cases) can be found in my Github repo.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Confirmed cases \nlibrary(tidyr)\n\nnames(data_confirmed)\n# First rename the two first columns using rename() function\nconfirmed_tidy <- data_confirmed %>%\n  rename(\n    Province = \"Province/State\",\n    Country = \"Country/Region\"\n  ) %>%\n  pivot_longer(\n    names_to = \"date\",\n    cols = 5:ncol(data_confirmed)\n  ) %>%\n  group_by(Province, Country, Lat, Long, date) %>%\n  summarise(\"Confirmed\" = sum(value, na.rm = T)) %>%\n  mutate(date = as.Date(date, \"%m/%d/%y\"))\n```\n:::\n\n\n#### **4. Stack all COVID19 and Lat Long metrics into a master file**\n\nThe final metrics set is made of recovered and death COVID19 cases, by country and by date. Countries and dates are displayed in rows and metrics in columns.The original data also includes two columns for latitude and longitude used later to produce a map using Leaflet package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Now we merge them together\nMAPDATA <- confirmed_tidy %>%\n  full_join(deceased_tidy)\n\nMAPDATAF <- MAPDATA %>%\n  # Now we merge them together\n  MAPDATA() <- confirmed_tidy %>%\n  full_join(deceased_tidy)\n\nMAPDATAF <- MAPDATA %>%\n  full_join(recovered_tidy) %>%\n  arrange(Province, Country, date) %>%\n  # Recode NA values into 0\n  mutate(\n    Confirmed = ifelse(is.na(Confirmed), 0, Confirmed),\n    Deaths = ifelse(is.na(Deaths), 0, Deaths),\n    Recovered = ifelse(is.na(Recovered), 0, Recovered)\n  )\n```\n:::\n\n\nAlong the process of building the final data set, I will produce several csv files to validate each data step.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfile_pathCHK <-('C://Pablo UK//43 R projects 2021//04 My Shiny app//04 Mycovid19 app//CHECKS/')\nFile_name <-'/MAPDATAF.csv' \nwrite.csv(MAPDATAF,paste0(file_pathCHK,File_name),row.names = T)\n```\n:::\n\n\nIt is important to ensure any missing value is left in the file to ensure Leaflet maps works properly.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMAPDATAG <- MAPDATAF %>% mutate(\n  Confirmed = ifelse(is.na(Confirmed), 0, Confirmed),\n  Deaths = ifelse(is.na(Deaths), 0, Deaths),\n  Recovered = ifelse(is.na(Recovered), 0, Recovered)\n)\n\nMAPDATAH <- MAPDATAG %>%\n  pivot_longer(\n    names_to = \"Metric\",\n    cols = c(\"Confirmed\", \"Deaths\", \"Recovered\")\n  ) %>%\n  ungroup()\n\nPLOT_LEAFLET_MAPS <- MAPDATAH %>%\n  pivot_wider(names_from = Metric, values_from = c(value))\n```\n:::\n\n\n#### **5. Final data wrangling output files**\n\nThe data wrangling step outputs two files required for the Shiny app: the first one contains COVID metrics plus Lat Long variable for Leaflet maps and the second includes COVID metrics to be merged with country population figures.\n\n##### **5.1 COVID metrics set including Lat Long variables for Leaflet maps**\n\nThe next step is to create a new data set fo be used in the map on the first tab. It will contain metric variables and Latitude and Longitude variables. The map will display using pop-up circles as tool tips the number of cases per country, and it will be animated using a timeline below the map.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMAPDATAH <- MAPDATAG %>%\n  pivot_longer(\n    names_to = \"Metric\",\n    cols = c(\"Confirmed\", \"Deaths\", \"Recovered\")\n  ) %>%\n  ungroup()\n\nDATAMAP <- MAPDATAH\nPLOT_LEAFLET <- DATAMAP %>%\n  pivot_wider(names_from = Metric, values_from = c(value))\n\nPLOT_LEAFLET_MAPS <- PLOT_LEAFLET\n\nsave.image(\"C:/Pablo UK/43 R projects 2021/04 My Shiny app/04 Mycovid19 app/PLOT LEAFLET MAPS.RData\")\n```\n:::\n\n\nThese are the set of metrics created for the map tab:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# This file weill be use to comparae COVID19 rates across different countries\nPLOT_LEAFLET2_conf <- PLOT_LEAFLET_MAPS %>%\n  select(Country, date, Confirmed) %>%\n  group_by(Country, date) %>%\n  summarise(\"Confirmed\" = sum(Confirmed, na.rm = T))\n\nPLOT_LEAFLET2_death <- PLOT_LEAFLET_MAPS %>%\n  select(Country, date, Deaths) %>%\n  group_by(Country, date) %>%\n  summarise(\"Death\" = sum(Deaths, na.rm = T))\n\nPLOT_LEAFLET2_Recov <- PLOT_LEAFLET_MAPS %>%\n  select(Country, date, Recovered) %>%\n  group_by(Country, date) %>%\n  summarise(\"Recovered\" = sum(Recovered, na.rm = T))\n\n# Join together\nPLOT_LEAFLET_RATES <- PLOT_LEAFLET2_conf %>%\n  full_join(PLOT_LEAFLET2_death) %>%\n  arrange(Country, date)\n\nPLOT_LEAFLET_RATES <- PLOT_LEAFLET_RATES %>%\n  full_join(PLOT_LEAFLET2_Recov) %>%\n  arrange(Country, date)\n\nPLOT_LEAFLET_CDR_NUM <- PLOT_LEAFLET_RATES\n\nsave.image(\"C:/Pablo UK/43 R projects 2021/04 My Shiny app/04 Mycovid19 app/PLOT LEAFLET CDR NUM.RData\")\n```\n:::\n\n\nOur final set to compute COVID19 population rates is displayed below:\n\n##### **5.2 COVID19 population rates**\n\nI want to include population figures to obtain 10,000 population rates for each metric (cases, recovered,deaths covid19 cases) I first created new variables for those rates and then I merged the population figures in using the world Bank API. The aim of this section is to download population figures required to compute the relevant metric rates \\*10,000 population from World bank Development Indicators API. All the details from this script can be found in the Github repository.\n\nJust to highlight three main tasks included in this population-rates sub-section:\n\n**a). The use of `Source()` function to bring another script that pulls 2019 countries population data from WDI API** The aim of this first section is to download population figures from the set of World Development Indicators provided by the World Bank data API.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# # Include population figures   \nsource(\"UI/ui_get_population_figures.R\", local = TRUE)\n```\n:::\n\n\nAfter downloading the requested data by using the World Bank's API, the resulting XMS file is formatted in long country-year format.\n\n**b). Cleaning WDI population data to match COVID19 country names list** This is performed by the script called “ui_get_population_figures.R” located in the Shiny folder structure within a specific folder for UI scripts Using a which statement, it accounts for country name mismatches between COVID and WDI data sources, so population data matches COVID19 metrics.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# LOAD population figures in the right way\n# Input missing values\nPOP_POPULATED <- POP_DATA_2019\n\nCNpop <- c(\n  \"Bahamas, The\", \"Brunei Darussalam\", \"Congo, Dem. Rep.\", \"Congo, Rep.\", \"Egypt, Arab Rep.\", \"Gambia, The\", \"Iran, Islamic Rep.\", \"Korea, Rep.\",\n  \"Kyrgyz Republic\", \"Micronesia, Fed. Sts.\", \"Russian Federation\", \"St. Kitts and Nevis\", \"St. Lucia\", \"St. Vincent and the Grenadines\",\n  \"Slovak Republic\", \"Syrian Arab Republic\", \"United States\", \"Venezuela, RB\", \"Yemen, Rep.\"\n)\n\nlength(CNpop)\n\nCNindic <- c(\n  \"Bahamas\", \"Brunei\", \"Congo (Brazzaville)\", \"Congo (Kinshasa)\", \"Egypt\", \"Gambia\", \"Iran\", \"Korea, South\",\n  \"Kyrgyzstan\", \"Micronesia\", \"Russia\", \"Saint Kitts and Nevis\", \"Saint Lucia\", \"Saint Vincent and the Grenadines\",\n  \"Slovakia\", \"Syria\", \"US\", \"Venezuela\", \"Yemen\"\n)\nlength(CNindic)\n\n# Then we replace those values\nPOP_POPULATED[which(POP_POPULATED$country %in% CNpop), \"country\"] <- CNindic\n```\n:::\n\n\n#### **6. Compute X10,000 population rates for selected metrics**\n\nTwo preliminary calculations are needed before rates for COVID19 confirmed, recovered and death cases are calculated:\n\nFirst the JHU cases data is based on cumulative data, so previous day is subtracted to obtain the daily count of events for each metrics\n\nCompute now rates based on daily figures. Get those rates as 7 previous days rolling average to smooth daily fluctuations. Finally a rounding calculation is done on calculated rates to avoid any decimal places\n\nThere are a couple of calculations needed before rates for COVID19 confirmed, recovered and death cases are calculated:\n\nFirst the JHU cases is based on cumulative data, so previous day is subtracted to obtain the daily count of events for each metrics.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nPOPG_RATES <- POPG %>%\n  arrange(Country, date) %>%\n  mutate(\n    ConD = Confirmed - lag(Confirmed, n = 1),\n    RecD = Recovered - lag(Recovered, n = 1),\n    DeathD = Death - lag(Death, n = 1)\n  )\ntail(POPG_RATES)\n```\n:::\n\n\nCompute now rates based on daily figures.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nPOPG_RATESF <- POPG_RATES %>%\n  select(Country, date, year, population, ConD, RecD, DeathD) %>%\n  mutate(\n    CONFR = ceiling(((ConD / population) * 10000)),\n    RECR = ceiling(((RecD / population) * 10000)),\n    DEATHR = ceiling(((DeathD / population) * 10000))\n  )\n\ntail(POPG_RATESF)\n```\n:::\n\n\nGet those rates as 7 previous days rolling average to smooth daily fluctuations.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(zoo)\n\nRATES7DGAVG <- POPRATESG %>%\n  group_by(Country) %>%\n  select(date, Country, population, ConD, RecD, DeathD) %>%\n  mutate(\n    CONF_ma07 = rollmean(ConD, k = 7, fill = NA),\n    REC_ma07 = rollmean(RecD, k = 7, fill = NA),\n    DEATH_ma07 = rollmean(DeathD, k = 7, fill = NA)\n  )\n```\n:::\n\n\nFinally there is a round done on calculated taxes to avoid any decimal places.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nPOP_POPULATEDT <- POP_POPULATED_RENAME %>%\n  mutate(\n    Confirmed_10000 = round(Confirmed_Rate, digits = 0),\n    Recovered_10000 = round(Recovered_Rate, digits = 0),\n    Deaths_10000 = round(Death_Rate, digits = 0)\n  )\n\nPOP_POPULATED <- POP_POPULATEDT %>%\n  select(\n    date, Country, Population, Confirmed, Recovered, Death,\n    Conf_7D_10000 = Confirmed_10000,\n    Rec_7D_10000 = Recovered_10000,\n    Death_7D_10000 = Deaths_10000\n  )\n\nPOP_POPULATED\n```\n:::\n\n\n#### **6.1 Data set with rates ready for Shiny app**\n\nThis is the final data set that goes into the shiny app\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(POP_POPULATED)\n```\n:::\n\n\n#### **7. Building the Shiny dashboard**\n\nOnce that all the data is ready to build the Shiny dashboard, there where three main tabs that I wanted to display on the dashboard:\n\nThe script for the dashboard can be quite long, and it is available in the Github repository at the end of this blog article. As a general design choice, I opted for a standard Sidebar layout, using `fluidrow` and column functions to arrange the plots layout on each tab.\n\nThis is an example of the functions used to populate the `infoBoxes` on top of the dashboard.\n\nThe reactive components used in the plots and the maps to produce several animations were created using a `input\\$Time_Slider` function.\n\n```\nui <- dashboardPage(\n  \n  dashboardHeader(title = \"COVID-19\"),\n  # This Sidebar menu allows us to include new items on the sidebar\n  dashboardSidebar(\n                    sidebarMenu(\n                    # Setting id makes input$tabs give the tabName of currently-selected tab\n                    id = \"tabs\",\n                    menuItem(\"About\", tabName = \"about\", icon = icon(\"desktop\")),\n                    menuItem(\"Map\", tabName = \"map\", icon = icon(\"map\")),\n                    menuItem(\"Plots\", tabName = \"plot\", icon = icon(\"wifi\")),\n                    menuItem(\"Forecast\", tabName = \"forecast\", icon = icon(\"chart-line\")))\n  )\n  ,\n  dashboardBody(  # Infobox: Total figures KPI world\n```\n\nThis is an example of the functions used to populate the `infoBoxes` on top of the dashboard.\n\n```\ndashboardBody(  # Infobox: Total figures KPI world\n    fluidRow(infoBoxOutput(\"Total_cases_WORLD\", width = 3),\n             infoBoxOutput(\"Total_recovered_WORLD\", width = 3),\n             infoBoxOutput(\"Total_deaths_WORLD\", width = 3),\n             infoBoxOutput(\"Date\", width = 3)\n             ),\n```\n\nThe reactive components used in the plots and the maps to produce several animations were created using a `input\\$Time_Slider` function.\n\n7.1. Interactive map with KPI and timeline\n\n-   Pop-up and tool tips display COVID19 Total, recovered and death cases\n\n-   Circles radius are proportional to number of cases per country\n\n-   Dynamic animation: Map changes as data varies in time\n\nMap tab\n\n**7.2. Interactive line charts using {plotly} library**\n\n-   KPI number of cases and day to day percent change\n\n-   Drop down menu to filter for specific countries\n\n-   Line chart cases by country, selected by drop down menu\n\n-   Top 10 country rates \\*10,000 cases\n\n-   Interactive plots to Zoom in and Zoom out using {plotly} library to display Top 10 country rates \\*10,000 cases\n\n**7.3. In development**\n\n-   My intention is to include a new tab in coming weeks to include a predictive modelling tool using some modelling tool such as tidy models or modeltime, just to test it. In the long run I would like to learn how to implement hierarchical Bayesian modelling into some dashboard.\n\n-   Also I would like to include a specific .CSS file in YAML section of the shiny dashboard to fine tuning the format applied on each tab.\n\nModeltime\n\n#### **8. Source code available in Github**\n\nAs this blog article was a brief description of the Shiny app I've designed, please follow the link below to get the source code from Github: `00 Maps data prep_SHINY_APP.R`, `01 Leaf and pop figures_SHINY_APP.R`, `02 ui_server_SHINY_APP.R`.\n\nSharing this script and connecting with other NHSR analysts will be good starting point to lean how to code consistently and also to follow a specific NHSR coding style when using R.\n\nAny comments to this blog article, please feel free to email me at: [pablo.leonrodenas\\@nhs.net](mailto:pablo.leonrodenas@nhs.net)\n\n\nThis blog has been edited for [NHS-R Style](https://nhsrway.nhsrcommunity.com/style-guides.html#referencing-r-packages-and-functions-in-text).\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}